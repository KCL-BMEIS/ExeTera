{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d220666f-dad8-4229-9f24-9d24925b5c25",
   "metadata": {},
   "source": [
    "<h1> 1, Import </h1>\n",
    "<p>ExeTera utlize HDF5 file format to acquire fast performance when processing the data. Hence the first step of using ExeTera is usually transform the file from other formats, e.g. csv, into HDF5.</p>\n",
    "<p>ExeTera provides utilities to transform the csv data into HDF5, through either command line or code. </p>\n",
    "<b>How import works</b>\n",
    "<p>\n",
    "a. Importing via the exetera import command:  <br>\n",
    "<em>\n",
    "exetera import <br>\n",
    "-s path/to/covid_schema.json \\  <br>\n",
    "-i \"patients:path/to/patient_data.csv, assessments:path/to/assessmentdata.csv,  <br> tests:path/to/covid_test_data.csv, diet:path/to/diet_study_data.csv\" \\  <br>\n",
    "-o /path/to/output_dataset_name.hdf5  <br>\n",
    "--include \"patients:(id,country_code,blood_group), assessments:(id,patient_id,chest_pain)\"  <br>\n",
    "--exclude \"tests:(country_code)\" </em>   <br>\n",
    "\n",
    "Arguments:  <br>\n",
    "-s/--schema: The location and name of the schema file  <br>\n",
    "-te/--territories: If set, this only imports the listed territories. If left unset, all territories are imported  <br>\n",
    "-i/--inputs : A comma separated list of 'name:file' pairs. This should be put in parentheses if it contains any whitespace. See the example above.  <br>\n",
    "-o/--output_hdf5: The path and name to where the resulting hdf5 dataset should be written  <br>\n",
    "-ts/--timestamp: An override for the timestamp to be written (defaults to datetime.now(timezone.utc))  <br>\n",
    "-w/--overwrite: If set, overwrite any existing dataset with the same name; appends to existing dataset otherwise  <br>\n",
    "-n/--include: If set, filters out all fields apart from those in the list.  <br>\n",
    "-x/--exclude: If set, filters out the fields in this list.  <br>\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "b. Importing through code <br>\n",
    "Use <em> importer.import_with_schema(timestamp, output_hdf5_name, schema, tokens, args.overwrite, include_fields, exclude_fields) </em>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febce312-098c-436a-a73f-ecea78c91047",
   "metadata": {},
   "source": [
    "<b>Import example</b>\n",
    "</br>\n",
    "For the import example, please refer to the example in RandomDataset. After you finish, please copy the hdf5 file here to continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2271e28e-21e1-4720-9c32-4aaf9b310546",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls *hdf5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d1a2cd-85cb-4ea5-b794-ea8e07779bfb",
   "metadata": {},
   "source": [
    "<h1>2, ExeTera Session and DataSet</h1>\n",
    "<p> \n",
    "Session instances are the top-level ExeTera class. They serve two main purposes: <br>\n",
    "\n",
    "1, Functionality for creating / opening / closing Dataset objects, as well as managing the lifetime of open datasets <br>\n",
    "2, Methods that operate on Fields <br>\n",
    "</p>\n",
    "<h3>Creating a session object</h3>\n",
    "<p>\n",
    "Creating a Session object can be done multiple ways, but we recommend that you wrap the session in a context manager (with statement). This allows the Session object to automatically manage the datasets that you have opened, closing them all once the with statement is exited. Opening and closing datasets is very fast. When working in jupyter notebooks or jupyter lab, please feel free to create a new Session object for each cell. <br>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ad07d9-df92-4668-bb2f-8964ea91018c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you should have exetera installed already, otherwise: pip install exetera\n",
    "import sys\n",
    "from exetera.core.session import Session\n",
    "\n",
    "# recommended\n",
    "with Session() as s:\n",
    "  ...\n",
    "\n",
    "# not recommended\n",
    "s = Session()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f771302f-0840-4cfb-856c-09dc2c39ade6",
   "metadata": {},
   "source": [
    "<h3>Loading dataset(s)</h3>\n",
    "Once you have a session, the next step is typically to open a dataset. Datasets can be opened in one of three modes: <br>\n",
    "\n",
    "read - the dataset can be read from but not written to <br>\n",
    "append - the dataset can be read from and written to <br>\n",
    "write - a new dataset is created (and will overwrite an existing dataset with the same name) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bd5317-bfa0-4a31-bf9c-3475f17c4afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Session() as s:\n",
    "  ds1 = s.open_dataset('user_assessments.hdf5', 'r', 'ds1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887f2a4a-b14c-4485-8a67-f2fb5312208f",
   "metadata": {},
   "source": [
    "<h3>Closing a dataset</h3>\n",
    "Closing a dataset is done through Session.close_dataset, as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2eaf21-ddc7-4b1a-8c63-4471ee8aee6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Session() as s:\n",
    "  ds1 = s.open_dataset('user_assessments.hdf5', 'r', 'ds1')\n",
    "\n",
    "  # do some work\n",
    "  print(ds1.keys())\n",
    "\n",
    "  s.close_dataset('ds1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d23b356-93e8-4db8-a0fa-c1573cc3695c",
   "metadata": {},
   "source": [
    "<h3>Dataset</h3>\n",
    "ExeTera works with HDF5 datasets under the hood, and the Dataset class is the means why which you interact with it at the top level. Each Dataset instance corresponds to a physical dataset that has been created or opened through a call to session.open_dataset. <br>\n",
    "\n",
    "Datasets are in turn used to create, access and delete DataFrames. Each DataFrame is a top-level HDF5 group that is intended to be very much like and familiar to the Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7f668f-9630-49cb-83f0-6ac32da9feb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from exetera.core import dataset\n",
    "\n",
    "with Session() as s:\n",
    "    ds = s.open_dataset('temp.hdf5', 'w', 'ds')\n",
    "\n",
    "    #Create a new dataframe\n",
    "    df = ds.create_dataframe('foo')\n",
    "    print(ds.keys())\n",
    "\n",
    "    #Rename a dataframe\n",
    "    ds['bar'] = ds['foo'] # internally performs a rename\n",
    "    print('Renamed:', ds.keys())\n",
    "    dataset.move(ds['bar'], ds, 'foo')\n",
    "    print('Moved:', ds.keys())\n",
    "\n",
    "    #Copy a dataframe within a dataset\n",
    "    dataset.copy(ds['foo'], ds, 'bar')\n",
    "    print('Copied:', ds.keys())\n",
    "    \n",
    "    #Delete an existing dataframe\n",
    "    ds.delete_dataframe(ds['foo'])\n",
    "    print('Dataframe foo deleted.', ds.keys())\n",
    "\n",
    "    #Copy a dataframe between datasets\n",
    "    ds2 = s.open_dataset('temp2.hdf5', 'w', 'ds2')\n",
    "    ds2['foobar'] = ds['bar']\n",
    "    print('Copied:', ds1.keys())\n",
    "    print('Copied:', ds2.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d12f984-35d1-4a90-a1ca-655afe7c80f3",
   "metadata": {},
   "source": [
    "<h1> 3, DataFrame and Fields </h1>\n",
    "The ExeTera DataFrame object is intended to be familiar to users of Pandas, albeit not identical. <br>\n",
    "\n",
    "ExeTera works with Datasets, which are backed up by physical key-value HDF5 datastores on drives, and, as such, there are necessarily some differences between the Pandas DataFrame: <br>\n",
    "\n",
    "- Pandas DataFrames enforce that all Series (Fields in ExeTera terms) are the same length. ExeTera doesn't require this, but there are then operations that do not make sense unless all fields are of the same length. ExeTera allows DataFrames to have fields of different lengths because the operation to apply filters and so for to a DataFrame would run out of memory on large DataFrames <br>\n",
    "- Types always matter in ExeTera. When creating new Fields (Pandas Series) you need to specify the type of the field that you would like to create. Fortunately, Fields have convenience methods to construct empty copies of themselves for when you need to create a field of a compatible type <br>\n",
    "- ExeTera DataFrames are new with the 0.5 release of ExeTera and do not yet support all of the operations that Panda DataFrames support. This functionality will be augmented in future releases. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5221d1da-8f36-4259-a800-3fadfc50600c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "with Session() as s:\n",
    "    ds = s.open_dataset('temp.hdf5', 'w', 'ds')\n",
    "    \n",
    "    #Create a new field\n",
    "    df = ds.create_dataframe('df')\n",
    "    i_f = df.create_indexed_string('i_foo')\n",
    "    f_f = df.create_fixed_string('f_foo', 8)\n",
    "    n_f = df.create_numeric('n_foo', 'int32')\n",
    "    c_f = df.create_categorical('c_foo', 'int8', {b'a': 0, b'b': 1})\n",
    "    t_f = df.create_timestamp('t_foo')\n",
    "\n",
    "\n",
    "    #Copy a field from another dataframe \n",
    "    df2 = ds.create_dataframe('df2')\n",
    "    df2['foo'] = df['i_foo']\n",
    "    df2['foobar'] = df2['foo']\n",
    "    print(df2.keys())\n",
    "\n",
    "\n",
    "    #Apply a filter to all fields in a dataframe\n",
    "    df = ds.create_dataframe('df3')\n",
    "    df.create_numeric('n_foo', 'int32').data.write([0,1,2,3,4,5,6,7,8,9])\n",
    "    filt = np.array([True if i%2==0 else False for i in range(0,10)])  # filter out odd values\n",
    "    df4 = ds.create_dataframe('df4')\n",
    "    df.apply_filter(filt, ddf=df4) # creates a new dataframe from the filtered dataframe\n",
    "    print('Original:', df['n_foo'].data[:])\n",
    "    print('Filtered: ',df4['n_foo'].data[:])\n",
    "    df.apply_filter(filt) # destructively filters the dataframe\n",
    "    print('Original:', df['n_foo'].data[:])\n",
    "\n",
    "\n",
    "    #Re-index all fields in a dataframe\n",
    "    df = ds.create_dataframe('df5')\n",
    "    df.create_numeric('n_foo', 'int32').data.write([0,1,2,3,4,5,6,7,8,9])\n",
    "    print('Previous re-index:', df['n_foo'].data[:])\n",
    "    inds =  np.array([9,8,7,6,5,4,3,2,1,0])\n",
    "    df6 = ds.create_dataframe('df6')\n",
    "    df.apply_index(inds, ddf=df6) # creates a new dataframe from the re-indexed dataframe\n",
    "    print('Re-indexed:', df6['n_foo'].data[:])\n",
    "    df.apply_index(inds) # destructively re-indexes the dataframe\n",
    "    print('Re-indexed:', df['n_foo'].data[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd4d459-d69d-4e33-be71-826f523a58d8",
   "metadata": {},
   "source": [
    "<h3>Fields </h3>\n",
    "The Field object is the analogy of the Pandas DataFrame Series or Numpy ndarray in ExeTera. Fields contain (often very large) arrays of a given data type, with an API that allows intuitive manipulations of the data. <br>\n",
    "\n",
    "<br>\n",
    "In order to store very large data arrays as efficiently as possible, Fields store their data in ways that may not be intuitive to people familiar with Pandas or Numpy. Numpy makes certain design decisions that reduce the flexibility of lists in order to gain speed and memory efficiency, and ExeTera does the same to further improve on speed and memory. The IndexedStringField, for example, uses two arrays, one containing a concatinated array of bytevalues from all of the strings in the field, and another array of indices indicating where each field starts and end. This is much faster and more memory efficient to iterate over than a Numpy string array when the variability of string lengths is very high. This kind of change however, creates a great deal of complexity when exposed to the user, and Field does its best to hide that away and act like a single array of string values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e56dc65-467a-45f7-a677-92d6386a345d",
   "metadata": {},
   "source": [
    "<h3>Accessing underlying data</h3>\n",
    "Underlying data can be accessed as follows: <br>\n",
    "\n",
    "All fields have a data property that provides access to the underlying data that they contain. For most field types, it is very efficient to read from and write to this property, provided it is done using slice syntax <br>\n",
    "- Indexed string fields provide data as a convenience method, but this should only be used when performance is not a consideration <br>\n",
    "- Indexed string fields provide indices and values properties should you need to interact with their underlying data efficiently and directly. For the most part, we discourage this and have tried to provide you with all of the methods that you need under the hood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c81326-19c0-4e2f-8ac8-6e44efc0a9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Session() as s:\n",
    "    ds = s.open_dataset('temp.hdf5', 'w', 'ds')\n",
    "    df = ds.create_dataframe('df')\n",
    "    df.create_numeric('field', 'int32').data.write([0,1,2,3,4,5,6,7,8,9])\n",
    "    print(df['field'].data[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a43a716-d53d-44d9-bf54-150975a983cd",
   "metadata": {},
   "source": [
    "Constructing compatible empty fields\n",
    "Fields have a create_like method that can be used to construct an empty field of a compatible type\n",
    "\n",
    "when called with no arguments, this creates an in-memory field that can be further manipulated before eventually being assigned to a DataFrame (or not)\n",
    "when called with a DataFrame and a name, it will create an empty field on that DataFrame of the given name that can subsequently be written to See below for examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa861df-84ee-48a9-8e42-1e6332d8b824",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Session() as s:\n",
    "    ds = s.open_dataset('temp.hdf5', 'w', 'ds')\n",
    "    df = ds.create_dataframe('df')\n",
    "    df.create_numeric('field', 'int32').data.write([0,1,2,3,4,5,6,7,8,9])\n",
    "    df['field'].create_like(df, 'field2')  # use create_like to create a field with similar data type\n",
    "    print(df['field'].data[:])\n",
    "    print(df['field2'].data[:])  # note the data is not copied"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96d7ddb-26d9-4933-93e5-f97e8bad2592",
   "metadata": {},
   "source": [
    "<h3>Arithmetic operations </h3>\n",
    "Numeric and timestamp fields have the standard set of arithmetic operations that can be applied to them: <br>\n",
    "\n",
    "These are +, -, *, /, //, %, and divmod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28619c4e-8dd0-49e1-9f69-d2e82c848c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Session() as s:\n",
    "    ds = s.open_dataset('temp.hdf5', 'w', 'ds')\n",
    "    df = ds.create_dataframe('df')\n",
    "    df.create_numeric('a', 'int32').data.write([0,1,2,3,4,5,6,7,8,9])\n",
    "    df.create_numeric('b', 'int32').data.write([0,1,2,3,4,5,6,7,8,9])\n",
    "\n",
    "    df['c'] = df['a'] + df['b']\n",
    "    print(df['c'].data[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8747c8-5fca-4b4b-bc58-5b0032a5a2e4",
   "metadata": {},
   "source": [
    "<h3>Element-wise logical operators</h3>\n",
    "Numeric fields can have logical operations performed on them on an element-wise basis <br>\n",
    "\n",
    "These are &, |, ^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5cfb09-4f5a-434d-9eab-4ddd7c2d9f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Session() as s:\n",
    "    ds = s.open_dataset('temp.hdf5', 'w', 'ds')\n",
    "    df = ds.create_dataframe('df')\n",
    "    df.create_numeric('a', 'bool').data.write([True if i%2 == 0 else False for i in range(0,10)])\n",
    "    df.create_numeric('b', 'bool').data.write([True if i%2 == 0 else False for i in range(0,10)])\n",
    "\n",
    "    filter1 = df['a'] & df['b']\n",
    "    print(filter1.data[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4731e2b7-7bf7-48e0-99ee-024bff1c6047",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Session() as s:\n",
    "    ds = s.open_dataset('temp.hdf5', 'w', 'ds')\n",
    "    df = ds.create_dataframe('df')\n",
    "    df.create_numeric('a', 'bool').data.write([True if i%2 == 0 else False for i in range(0,10)])\n",
    "    df.create_numeric('b', 'bool').data.write([True if i%2 == 1 else False for i in range(0,10)])\n",
    "\n",
    "    filter1 = df['a'] | df['b']\n",
    "    print(filter1.data[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a1c302-94d0-40ab-be13-e5f7eb6c171d",
   "metadata": {},
   "source": [
    "<h3>Comparison operators</h3>\n",
    "Numeric, categorical and timestamp fields have comparison operations that can be applied to them: <br>\n",
    "\n",
    "These are <, <=, ==, |=, >=, >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae438918-d810-46c0-a1ad-376c8189444f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Session() as s:\n",
    "    ds = s.open_dataset('temp.hdf5', 'w', 'ds')\n",
    "    df = ds.create_dataframe('df')\n",
    "    df.create_numeric('a', 'bool').data.write([True if i%2 == 0 else False for i in range(0,10)])\n",
    "    df.create_numeric('b', 'bool').data.write([True if i%2 == 1 else False for i in range(0,10)])\n",
    "\n",
    "    filter1 = df['a'] ==  df['b']\n",
    "    print(filter1.data[:])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
