{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a133c850-1cc3-4ee5-830a-9440e70cd90c",
   "metadata": {},
   "source": [
    "# Advanced Operations Example\n",
    "\n",
    "This example uses the user_assessments hdfs file from RandomDataset. User assessments file contains a user table and a assessments table, that imitate the data structure of in CSS (Covid Symptom Study) project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac06eae4-8214-4e96-a419-d361698825a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.hdf5  temp2.hdf5  temp.hdf5  user_assessments.hdf5\n"
     ]
    }
   ],
   "source": [
    "!ls *hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4eae8d06-0872-4e30-b6c8-2e8ba86fe9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['assessments', 'users'])\n",
      "Columns in users table: odict_keys(['FirstName', 'LastName', 'bmi', 'bmi_valid', 'has_diabetes', 'height_cm', 'height_cm_valid', 'id', 'j_valid_from', 'j_valid_to', 'year_of_birth', 'year_of_birth_valid'])\n",
      "fields\t            bmi\t   has_diabetes\t      height_cm\t  year_of_birth\t\n",
      "count\t             10\t             10\t             10\t             10\t\n",
      "unique\t            NaN\t              1\t            NaN\t            NaN\t\n",
      "top\t            NaN\t              0\t            NaN\t            NaN\t\n",
      "freq\t            NaN\t             10\t            NaN\t            NaN\t\n",
      "mean\t          31.70\t            NaN\t         135.60\t        1965.40\t\n",
      "std\t           5.14\t            NaN\t          25.39\t          24.87\t\n",
      "min\t          25.00\t            NaN\t         107.00\t        1926.00\t\n",
      "25%\t          25.02\t            NaN\t         107.20\t        1926.07\t\n",
      "50%\t          25.05\t            NaN\t         107.41\t        1926.13\t\n",
      "75%\t          25.07\t            NaN\t         107.61\t        1926.20\t\n",
      "max\t          39.00\t            NaN\t         190.00\t        2004.00\t\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fields': ['bmi', 'has_diabetes', 'height_cm', 'year_of_birth'],\n",
       " 'count': [10, 10, 10, 10],\n",
       " 'mean': ['31.70', 'NaN', '135.60', '1965.40'],\n",
       " 'std': ['5.14', 'NaN', '25.39', '24.87'],\n",
       " 'min': ['25.00', 'NaN', '107.00', '1926.00'],\n",
       " '25%': ['25.02', 'NaN', '107.20', '1926.07'],\n",
       " '50%': ['25.05', 'NaN', '107.41', '1926.13'],\n",
       " '75%': ['25.07', 'NaN', '107.61', '1926.20'],\n",
       " 'max': ['39.00', 'NaN', '190.00', '2004.00'],\n",
       " 'unique': ['NaN', 1, 'NaN', 'NaN'],\n",
       " 'top': ['NaN', 0, 'NaN', 'NaN'],\n",
       " 'freq': ['NaN', 10, 'NaN', 'NaN']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from exetera.core.session import Session\n",
    "s = Session()  # not recommended, but to cover all the cells in the example, we use this way here\n",
    "src = s.open_dataset('user_assessments.hdf5', 'r', 'src')\n",
    "print(src.keys())\n",
    "users = src['users']\n",
    "print('Columns in users table:', users.keys())\n",
    "# use describe to check the value in each column\n",
    "users.describe(include=['bmi', 'has_diabetes', 'height_cm',  'year_of_birth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67d79440-4c2d-42ec-8f62-3d10bc72e3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in users table: odict_keys(['abdominal_pain', 'brain_fog', 'date', 'id', 'j_valid_from', 'j_valid_to', 'loss_of_smell', 'temperature_f', 'temperature_f_valid', 'tested_covid_positive', 'user_id'])\n",
      "fields\t abdominal_pain\t      brain_fog\t           date\t  loss_of_smell\t  temperature_f\t\n",
      "count\t             30\t             30\t             30\t             30\t             30\t\n",
      "unique\t              1\t              1\t            NaN\t              1\t            NaN\t\n",
      "top\t              0\t              0\t            NaN\t              0\t            NaN\t\n",
      "freq\t             30\t             30\t            NaN\t             30\t            NaN\t\n",
      "mean\t            NaN\t            NaN\t  1628912712.34\t            NaN\t         101.36\t\n",
      "std\t            NaN\t            NaN\t    10077317.46\t            NaN\t           4.33\t\n",
      "min\t            NaN\t            NaN\t  1613872118.68\t            NaN\t          95.23\t\n",
      "25%\t            NaN\t            NaN\t  1613975491.70\t            NaN\t          95.24\t\n",
      "50%\t            NaN\t            NaN\t  1614078864.72\t            NaN\t          95.26\t\n",
      "75%\t            NaN\t            NaN\t  1614182237.74\t            NaN\t          95.28\t\n",
      "max\t            NaN\t            NaN\t  1644821469.46\t            NaN\t         109.64\t\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fields': ['abdominal_pain',\n",
       "  'brain_fog',\n",
       "  'date',\n",
       "  'loss_of_smell',\n",
       "  'temperature_f'],\n",
       " 'count': [30, 30, 30, 30, 30],\n",
       " 'mean': ['NaN', 'NaN', '1628912712.34', 'NaN', '101.36'],\n",
       " 'std': ['NaN', 'NaN', '10077317.46', 'NaN', '4.33'],\n",
       " 'min': ['NaN', 'NaN', '1613872118.68', 'NaN', '95.23'],\n",
       " '25%': ['NaN', 'NaN', '1613975491.70', 'NaN', '95.24'],\n",
       " '50%': ['NaN', 'NaN', '1614078864.72', 'NaN', '95.26'],\n",
       " '75%': ['NaN', 'NaN', '1614182237.74', 'NaN', '95.28'],\n",
       " 'max': ['NaN', 'NaN', '1644821469.46', 'NaN', '109.64'],\n",
       " 'unique': [1, 1, 'NaN', 1, 'NaN'],\n",
       " 'top': [0, 0, 'NaN', 0, 'NaN'],\n",
       " 'freq': [30, 30, 'NaN', 30, 'NaN']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asmts = src['assessments']\n",
    "print('Columns in users table:', asmts.keys())\n",
    "asmts.describe(include=['abdominal_pain', 'brain_fog', 'date','loss_of_smell', 'temperature_f'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be7ec97-a8d2-449f-9f57-e54a4effb52c",
   "metadata": {},
   "source": [
    "## 4.Filtering\n",
    "Filtering is performed through the use of the apply_filter function. This can be performed on __individual fields__ or at a __dataframe level__. apply_filter applies the filter on data rows.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dab8e873-cf1f-47c5-bebb-18bde4357543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9  adults out of  10  total subjects found.\n"
     ]
    }
   ],
   "source": [
    "with Session() as s:\n",
    "    dst = s.open_dataset('temp2.hdf5', 'w', 'dst')\n",
    "    df = dst.create_dataframe('df')\n",
    "\n",
    "    # apply a filter to the dataframe\n",
    "\n",
    "    filt = (2022 - users['year_of_birth'].data[:]) > 18\n",
    "    users.apply_filter(filt, ddf=df)  # non-destructive with ddf argument\n",
    "    print(len(df['id']), ' adults out of ', len(users['id']), ' total subjects found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c336d758-878a-4df6-8458-cc3ddf280964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True False  True  True  True  True]\n",
      "[b'0' b'1' b'2' b'3' b'4' b'6' b'7' b'8' b'9']\n"
     ]
    }
   ],
   "source": [
    "# Combining filters\n",
    "# we can make use of fields directly rather than fetching the underlying numpy arrays\n",
    "# we recommend this approach in general\n",
    "\n",
    "filt = ((2022 - users['year_of_birth'].data[:]) > 18) & (users['has_diabetes'].data[:] == False)\n",
    "print(filt)\n",
    "\n",
    "# fetching numpy arrays\n",
    "print(users['id'].data[filt])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3316eb91-2b59-46d9-9f4f-1262192d6807",
   "metadata": {},
   "source": [
    "## 5.Performance boost using numba\n",
    "\n",
    "As the underlying data is fetched as a numpy array, you can utlize the numba @njit functions to accelarate the data process. For example in the case of summing up symptoms, use a seperate function with @njit decrator can speed up the performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c89f52b9-f96d-4e36-a8e3-67953aaedae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.901110410690308\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "#sum up the symptoms without njit\n",
    "test_length = 3000000000  # here we use the a test length rather than 50 rows in the dataset, \n",
    "                            # as the difference comes with more rows\n",
    "symptoms = ['abdominal_pain', 'brain_fog',  'loss_of_smell']\n",
    "symp_data = {}\n",
    "for i in symptoms:\n",
    "    symp_data[i] = np.zeros(test_length, 'int32')\n",
    "t0 = time.time()\n",
    "sum_symp = np.zeros(test_length, 'int32')\n",
    "for i in symptoms:\n",
    "    sum_symp += symp_data[i]\n",
    "#print(sum_symp)\n",
    "print(time.time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "202321d4-b1fc-47bd-8878-779df121c913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.684003591537476\n"
     ]
    }
   ],
   "source": [
    "#sum up the symptoms with njit\n",
    "from numba import njit\n",
    "\n",
    "@njit\n",
    "def sum_symptom(symp_data, sum_data):\n",
    "    sum_data += symp_data\n",
    "    return sum_data\n",
    "\n",
    "t0 = time.time()\n",
    "sum_symp = np.zeros(test_length, 'int32')\n",
    "for i in symptoms:\n",
    "    sum_symp = sum_symptom(symp_data[i], sum_symp)\n",
    "#print(sum_symp)\n",
    "print(time.time()-t0)  # usually 10x faster dependents on data size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2723a9c9-36a5-4737-870c-7b4d130307f8",
   "metadata": {},
   "source": [
    "## 6.Groupby\n",
    "\n",
    "The groupby is similar to the groupby api from Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acfec7b4-01ec-4bf5-b8d3-d99a9db98273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 30\n",
      "10 30\n",
      "10 30\n",
      "10 30\n"
     ]
    }
   ],
   "source": [
    "with Session() as s:\n",
    "    dst = s.open_dataset('temp2.hdf5', 'w', 'dst')\n",
    "    df = dst.create_dataframe('df')\n",
    "    #drop duplicates\n",
    "    asmts.drop_duplicates(by = 'user_id', ddf = df)\n",
    "    print(len(df['user_id']), len(asmts['user_id']))\n",
    "    \n",
    "    #count\n",
    "    df2 = dst.create_dataframe('df2')\n",
    "    asmts.groupby(by = 'user_id').count(ddf = df2)\n",
    "    print(len(df2['user_id']), len(asmts['user_id']))\n",
    "    \n",
    "    #min/ max\n",
    "    df3 = dst.create_dataframe('df3')\n",
    "    asmts.groupby(by = 'user_id').max(target ='date', ddf = df3)\n",
    "    print(len(df3['user_id']), len(asmts['user_id']))\n",
    "    df4 = dst.create_dataframe('df4')\n",
    "    asmts.groupby(by = 'user_id').min(target ='date', ddf = df4)\n",
    "    print(len(df4['user_id']), len(asmts['user_id']))\n",
    "\n",
    "    #first/last\n",
    "    df5 = dst.create_dataframe('df5')\n",
    "    asmts.groupby(by = 'user_id').first(target ='date', ddf = df5)\n",
    "    df6 = dst.create_dataframe('df6')\n",
    "    asmts.groupby(by = 'user_id').last(target ='date', ddf = df6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdd38f7-e8a7-4ad6-80ad-d0ff45401524",
   "metadata": {},
   "source": [
    "Apart from the groupby, pandas also provide the transform functions. In Transform, the data length is not alterd. Here in ExeTera, we do not have a dedicate API for transform functions, but the same operation can be done via the span:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29ef8595-6835-4f0d-a5bf-6ee15bf8eabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "#transform rather than group by\n",
    "with Session() as s:\n",
    "    dst = s.open_dataset('temp2.hdf5', 'w', 'dst')\n",
    "    df = dst.create_dataframe('df')\n",
    "    \n",
    "    symptoms = ['abdominal_pain', 'brain_fog',  'loss_of_smell']\n",
    "    sum_symp = np.zeros(len(asmts['user_id']), 'int32')\n",
    "    for i in symptoms:\n",
    "        sum_symp += np.zeros(len(asmts['user_id']), 'int32')\n",
    "    \n",
    "    spans = asmts['user_id'].get_spans()  # make sure asmts dataframe is sorted based on user_id\n",
    "    max_symp = np.zeros(len(asmts['user_id']), 'int32')\n",
    "    for i in range(len(spans)-1):\n",
    "        max_symp[spans[i]:spans[i+1]] = np.max(sum_symp.data[spans[i]:spans[i+1]])\n",
    "    #write data back to df\n",
    "    df.create_numeric('max_symp', 'int32').data.write(max_symp)\n",
    "    print(len(df['max_symp'].data))  # note the field length is the same with transform\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e5314b-d130-4ded-a41a-ca7fda798ae1",
   "metadata": {},
   "source": [
    "## 7.Join\n",
    "\n",
    "ExeTera provides functions that provide pandas-like merge functionality on DataFrame instances. We have made this operation as familiar as possible to Pandas users, but there are a couple of differences that we should highlight:\n",
    "\n",
    "\n",
    "1) merge is provided as a function in the dataframe unit, rather than as a member function on DataFrame instances \n",
    "\n",
    "\n",
    "2) merge takes three dataframe arguments, left, right and dest. This is due to the fact that DataFrames are always backed up by a datastore and so rather than create an in-memory destination dataframe, the resulting merged fields must be written to a dataframe of your choosing. \n",
    "\n",
    "\n",
    "3) Note, this can either be a separate dataframe or it can be the dataframe that you are merging to (typically left in the case of a \"left\" merge and right in the case of a \"right\" merge\n",
    "\n",
    "\n",
    "4) merge takes a number of optional hint fields that can save time when working with large datasets. These specify whether the keys are unique or ordered and allow the merge to occur without first checking this\n",
    "\n",
    "\n",
    "5) merge has a number of highly scalable algorithms that can be used when the key data is sorted and / or unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85261f6a-ba35-45a0-ba88-60a99a16ebe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "odict_keys(['FirstName', 'LastName', 'bmi', 'bmi_valid', 'has_diabetes', 'height_cm', 'height_cm_valid', 'id_l', 'j_valid_from_l', 'j_valid_to_l', 'year_of_birth', 'year_of_birth_valid', 'abdominal_pain', 'brain_fog', 'date', 'id_r', 'j_valid_from_r', 'j_valid_to_r', 'loss_of_smell', 'temperature_f', 'temperature_f_valid', 'tested_covid_positive', 'user_id'])\n"
     ]
    }
   ],
   "source": [
    "from exetera.core.dataframe import merge\n",
    "with Session() as s:\n",
    "    dst = s.open_dataset('temp2.hdf5', 'w', 'dst')\n",
    "    df = dst.create_dataframe('df')\n",
    "    merge(users, asmts, df, left_on='id', right_on='user_id', how='left')\n",
    "    print(len(df['id_l'].data))  # note as there are 'id' field in both dataframe, thus a suffix '_l' and '_r'\n",
    "                                    # are added to the merged dataframe \n",
    "    print(df.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899c862b-9a2a-4e08-8a5b-d7c2cadaf7b1",
   "metadata": {},
   "source": [
    "## 8.Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f72666d8-a5e3-48e9-859d-1d1e56b4a768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted ('id_l',) index in 0.0001354217529296875s\n",
      "  'FirstName' reordered in 0.2100369930267334s\n",
      "  'LastName' reordered in 0.0011086463928222656s\n",
      "  'bmi' reordered in 0.0004885196685791016s\n",
      "  'bmi_valid' reordered in 0.0004451274871826172s\n",
      "  'has_diabetes' reordered in 0.0017483234405517578s\n",
      "  'height_cm' reordered in 0.0004525184631347656s\n",
      "  'height_cm_valid' reordered in 0.00041365623474121094s\n",
      "  'id_l' reordered in 0.000408172607421875s\n",
      "  'j_valid_from_l' reordered in 0.00040650367736816406s\n",
      "  'j_valid_to_l' reordered in 0.0003733634948730469s\n",
      "  'year_of_birth' reordered in 0.00042748451232910156s\n",
      "  'year_of_birth_valid' reordered in 0.0006887912750244141s\n",
      "  'abdominal_pain' reordered in 0.0015702247619628906s\n",
      "  'brain_fog' reordered in 0.002073049545288086s\n",
      "  'date' reordered in 0.0006480216979980469s\n",
      "  'id_r' reordered in 0.0005962848663330078s\n",
      "  'j_valid_from_r' reordered in 0.00048804283142089844s\n",
      "  'j_valid_to_r' reordered in 0.0003993511199951172s\n",
      "  'loss_of_smell' reordered in 0.0014781951904296875s\n",
      "  'temperature_f' reordered in 0.00043654441833496094s\n",
      "  'temperature_f_valid' reordered in 0.0004210472106933594s\n",
      "  'tested_covid_positive' reordered in 0.0016057491302490234s\n",
      "  'user_id' reordered in 0.0004360675811767578s\n",
      "fields reordered in 0.22782111167907715s\n"
     ]
    }
   ],
   "source": [
    "from exetera.core.dataframe import merge\n",
    "with Session() as s:\n",
    "    dst = s.open_dataset('temp2.hdf5', 'w', 'dst')\n",
    "    df = dst.create_dataframe('df')\n",
    "    merge(users, asmts, df, left_on='id', right_on='user_id', how='left')\n",
    "    s.sort_on(df, df, ('id_l',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d77e233-16ed-4333-bec8-e8bc8f0e297d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted ('id_l',) index in 0.00015783309936523438s\n",
      "  'FirstName' reordered in 0.003790140151977539s\n",
      "  'LastName' reordered in 0.003641843795776367s\n",
      "  'bmi' reordered in 0.002112150192260742s\n",
      "  'bmi_valid' reordered in 0.0016775131225585938s\n",
      "  'has_diabetes' reordered in 0.0033807754516601562s\n",
      "  'height_cm' reordered in 0.0017406940460205078s\n",
      "  'height_cm_valid' reordered in 0.0017364025115966797s\n",
      "  'id_l' reordered in 0.0030646324157714844s\n",
      "  'j_valid_from_l' reordered in 0.0018968582153320312s\n",
      "  'j_valid_to_l' reordered in 0.001705169677734375s\n",
      "  'year_of_birth' reordered in 0.0018277168273925781s\n",
      "  'year_of_birth_valid' reordered in 0.0019350051879882812s\n",
      "  'abdominal_pain' reordered in 0.003263711929321289s\n",
      "  'brain_fog' reordered in 0.0048716068267822266s\n",
      "  'date' reordered in 0.002129793167114258s\n",
      "  'id_r' reordered in 0.00180816650390625s\n",
      "  'j_valid_from_r' reordered in 0.0025141239166259766s\n",
      "  'j_valid_to_r' reordered in 0.001980304718017578s\n",
      "  'loss_of_smell' reordered in 0.0038106441497802734s\n",
      "  'temperature_f' reordered in 0.002017974853515625s\n",
      "  'temperature_f_valid' reordered in 0.0025076866149902344s\n",
      "  'tested_covid_positive' reordered in 0.0039484500885009766s\n",
      "  'user_id' reordered in 0.002045869827270508s\n",
      "fields reordered in 0.06040382385253906s\n"
     ]
    }
   ],
   "source": [
    "from exetera.core.dataframe import merge\n",
    "with Session() as s:\n",
    "    dst = s.open_dataset('temp2.hdf5', 'w', 'dst')\n",
    "    df = dst.create_dataframe('df')\n",
    "    merge(users, asmts, df, left_on='id', right_on='user_id', how='left')\n",
    "    df2 = dst.create_dataframe('df2')\n",
    "    s.sort_on(df, df2, ('id_l',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e1396c8-e851-4e77-ba43-9ec4f9d01062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'0' b'0' b'0' b'1' b'1' b'1' b'2' b'2' b'2' b'3' b'3' b'3' b'4' b'4'\n",
      " b'4' b'5' b'5' b'5' b'6' b'6' b'6' b'7' b'7' b'7' b'8' b'8' b'8' b'9'\n",
      " b'9' b'9']\n",
      "[b'0' b'0' b'0' b'1' b'1' b'1' b'2' b'2' b'2' b'3' b'3' b'3' b'4' b'4'\n",
      " b'4' b'5' b'5' b'5' b'6' b'6' b'6' b'7' b'7' b'7' b'8' b'8' b'8' b'9'\n",
      " b'9' b'9']\n"
     ]
    }
   ],
   "source": [
    "#sorting with an index\n",
    "with Session() as s:\n",
    "    dst = s.open_dataset('temp2.hdf5', 'w', 'dst')\n",
    "    df = dst.create_dataframe('df')\n",
    "    merge(users, asmts, df, left_on='id', right_on='user_id', how='left')\n",
    "\n",
    "    index = s.dataset_sort_index((df['id_l'],))\n",
    "\n",
    "    # apply indices to a destination dataframe\n",
    "    df2 = dst.create_dataframe('df2')\n",
    "    df.apply_index(index, df2)\n",
    "    print(df2['id_l'].data[:])\n",
    "    \n",
    "    # apply indices in place\n",
    "    df.apply_index(index)\n",
    "    print(df['id_l'].data[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e2a9e4-400a-44e9-b08e-ef5f282bf6bd",
   "metadata": {},
   "source": [
    "## 9. I/O\n",
    "You can output an ExeTera dataframe back to csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7c67e89-1651-41b6-9f76-697875a82d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Session() as s:\n",
    "    dst = s.open_dataset('temp2.hdf5', 'w', 'dst')\n",
    "    df = dst.create_dataframe('df')\n",
    "    merge(users, asmts, df, left_on='id', right_on='user_id', how='left')\n",
    "\n",
    "    #output a dataframe to to_csv\n",
    "    df.to_csv('merged.csv')\n",
    "\n",
    "    #output to csv with row filters\n",
    "    row_filter = (2022-df['year_of_birth'].data[:]) > 18\n",
    "    df.to_csv('adults.csv', row_filter)  # save the data you want without change the underlying data in df\n",
    "\n",
    "    #output to csv with column filters\n",
    "    df.to_csv('column_filtered.csv', column_filter=['id_l', 'year_of_birth', 'date', 'tested_covid_positive'])  # save the columns you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12c08d25-f2ee-41c1-a5e8-73a34f5d94a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adults.csv  assessments.csv  column_filtered.csv  merged.csv  users.csv\n"
     ]
    }
   ],
   "source": [
    "!ls *csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a58d47e2-7237-4cd4-938a-4ad50d2ceda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# close src dataset as we open dataset using s=Session()\n",
    "# this is not necessary if we use context management by with Session as s:\n",
    "s.close_dataset(src)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
